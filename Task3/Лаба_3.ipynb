{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Лаба 3\n",
    "\n",
    "**Дедлайн**: 9 декабря\n",
    "\n",
    "**Задача**: разобраться в описанном ниже коде, используемой/используемых моделях, ответить на указанные вопросы и сгенерировать faceswap со своей фотографией\n",
    "\n",
    "**Описание**\n",
    "\n",
    "Порой, вместо самостоятельного написания нейросети и ее обучения (или дообучения) приходится использовать уже готовые модели и разбираться, как они устроены - будь то код в репозитории на Github-e, Jupyter Notebook или специальная библиотека с небольшой документацией. В данном задании вам предлагается решить эту задачу - разобраться с уже готовой моделью, успешно запустить ее, залезть в сорсы и посмотреть, как крупная модель устроена изнутри.\n",
    "\n",
    "В качестве решения лабораторной ожидается отчет в конце этого Jupyter Notebook-a с результатами генерации по вашим изображениям и ответами на следующие вопросы:\n",
    "\n",
    "1. Где расположен код модели и кто разработчик?\n",
    "2. Есть ли статья по работе модели? Если да, то в чем суть подхода авторов, как обучалась модель, какие метрики были достигнуты?\n",
    "3. Состоит ли модель из нескольких частей? Если да, то из каких, что они делают и как называются в коде?\n",
    "4. Как проходит процесс инференса модели для фото и видео (подробно)? Какие применяются преобразования входных и выходных данных?\n",
    "5. Можно ли дообучить модель и какие для этого требуются ресурсы? Может, авторы давали советы по обучению/дообучению? "
   ],
   "metadata": {
    "id": "rtMxIve8eZnQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GHOST: Generative High-fidelity One Shot Transfer"
   ],
   "metadata": {
    "id": "VYMolZvRtrqx"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"https://drive.google.com/uc?export=view&id=1MdOWxP9CqyqmW6t9MQ6-gcfEux54zbqP\">"
   ],
   "metadata": {
    "id": "5tVMVEIWxycf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#@markdown #**Check GPU and CUDA version**\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "!nvcc --version"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34JxjB_1sifK",
    "outputId": "51e6325a-947f-44b6-ab86-f0b11dd86ee3"
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May  8 01:06:03 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 531.18                 Driver Version: 531.18       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060 Ti    WDDM | 00000000:26:00.0  On |                  N/A |\n",
      "| 30%   37C    P8               23W / 200W|   1667MiB /  8192MiB |      2%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1136    C+G   ...ir\\CORSAIR iCUE 4 Software\\iCUE.exe    N/A      |\n",
      "|    0   N/A  N/A      1476    C+G   C:\\Program Files\\LGHUB\\lghub.exe          N/A      |\n",
      "|    0   N/A  N/A      3872    C+G   ...oogle\\Chrome\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A      4436    C+G   ..._8wekyb3d8bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A      9388    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     10756    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     10984    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     11956    C+G   ...64__8wekyb3d8bbwe\\CalculatorApp.exe    N/A      |\n",
      "|    0   N/A  N/A     12756    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     13708    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe    N/A      |\n",
      "|    0   N/A  N/A     14900    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     14996    C+G   ...al\\Discord\\app-1.0.9013\\Discord.exe    N/A      |\n",
      "|    0   N/A  N/A     15708    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     16020    C+G   ...223.8617.48\\jbr\\bin\\jcef_helper.exe    N/A      |\n",
      "|    0   N/A  N/A     16824    C+G   ...on\\wallpaper_engine\\wallpaper64.exe    N/A      |\n",
      "|    0   N/A  N/A     18452    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A     19100    C+G   ...b3d8bbwe\\Microsoft.Media.Player.exe    N/A      |\n",
      "|    0   N/A  N/A     23712    C+G   ...1.0_x64__8wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
      "|    0   N/A  N/A     24456    C+G   ...AppData\\Roaming\\Spotify\\Spotify.exe    N/A      |\n",
      "|    0   N/A  N/A     24924    C+G   ...B\\system_tray\\lghub_system_tray.exe    N/A      |\n",
      "|    0   N/A  N/A     26116    C+G   ...aming\\Telegram Desktop\\Telegram.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvcc' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#@markdown #**Clone github & download models**\n",
    "\n",
    "# !git clone https://github.com/sberbank-ai/sber-swap.git\n",
    "%cd sber-swap\n",
    "\n",
    "# # load arcface\n",
    "# !wget -P ./arcface_model https://github.com/sberbank-ai/sber-swap/releases/download/arcface/backbone.pth\n",
    "# !wget -P ./arcface_model https://github.com/sberbank-ai/sber-swap/releases/download/arcface/iresnet.py\n",
    "#\n",
    "# # load landmarks detector\n",
    "# !wget -P ./insightface_func/models/antelope https://github.com/sberbank-ai/sber-swap/releases/download/antelope/glintr100.onnx\n",
    "# !wget -P ./insightface_func/models/antelope https://github.com/sberbank-ai/sber-swap/releases/download/antelope/scrfd_10g_bnkps.onnx\n",
    "#\n",
    "# # load model itself\n",
    "# !wget -P ./weights https://github.com/sberbank-ai/sber-swap/releases/download/sber-swap-v2.0/G_unet_2blocks.pth\n",
    "#\n",
    "# # load super res model\n",
    "# !wget -P ./weights https://github.com/sberbank-ai/sber-swap/releases/download/super-res/10_net_G.pth"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nDRBmMbDiR6R",
    "outputId": "fc53322d-bca9-4e1f-c589-026685db23d5"
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anast3t\\Desktop\\all\\coding\\neural-networks\\Task3\\sber-swap\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#@markdown #**Install required libraries**\n",
    "\n",
    "# !pip install mxnet-cu112\n",
    "# !pip install onnxruntime-gpu==1.8\n",
    "# !pip install insightface==0.2.1\n",
    "# !pip install kornia==0.5.4"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sL5OeF3IqBNa",
    "outputId": "dba08d7c-dff0-4dc9-ae07-91f74882a5d5"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#@markdown #**Preparation**\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "from utils.inference.image_processing import crop_face, get_final_image, show_images\n",
    "from utils.inference.video_processing import read_video, get_target, get_final_video, add_audio_from_another_video, face_enhancement\n",
    "from utils.inference.core import model_inference\n",
    "\n",
    "from network.AEI_Net import AEI_Net\n",
    "from coordinate_reg.image_infer import Handler\n",
    "from insightface_func.face_detect_crop_multi import Face_detect_crop\n",
    "from arcface_model.iresnet import iresnet100\n",
    "from models.pix2pix_model import Pix2PixModel\n",
    "from models.config_sr import TestOptions"
   ],
   "metadata": {
    "id": "H6pX8e9JtBhW",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e382fb35-1649-466a-95b8-384faa8519dc"
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anast3t\\miniconda3\\envs\\task3-face-swap\\lib\\site-packages\\kornia\\augmentation\\augmentation.py:1833: DeprecationWarning: GaussianBlur is no longer maintained and will be removed from the future versions. Please use RandomGaussianBlur instead.\n",
      "  category=DeprecationWarning,\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#@markdown #**Initialize models**\n",
    "\n",
    "app = Face_detect_crop(name='antelope', root='./insightface_func/models')\n",
    "app.prepare(ctx_id= 0, det_thresh=0.6, det_size=(640,640))\n",
    "\n",
    "# main model for generation\n",
    "G = AEI_Net(backbone='unet', num_blocks=2, c_id=512)\n",
    "G.eval()\n",
    "G.load_state_dict(torch.load('weights/G_unet_2blocks.pth', map_location=torch.device('cpu')))\n",
    "G = G.cuda()\n",
    "G = G.half()\n",
    "\n",
    "# arcface model to get face embedding\n",
    "netArc = iresnet100(fp16=False)\n",
    "netArc.load_state_dict(torch.load('arcface_model/backbone.pth'))\n",
    "netArc=netArc.cuda()\n",
    "netArc.eval()\n",
    "\n",
    "# model to get face landmarks\n",
    "handler = Handler('./coordinate_reg/model/2d106det', 0, ctx_id=0, det_size=640)\n",
    "\n",
    "# model to make superres of face, set use_sr=True if you want to use super resolution or use_sr=False if you don't\n",
    "use_sr = True\n",
    "if use_sr:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    opt = TestOptions()\n",
    "    #opt.which_epoch ='10_7'\n",
    "    model = Pix2PixModel(opt)\n",
    "    model.netG.train()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-up7FWmYtDL4",
    "outputId": "4294b9d7-0301-452b-c78c-61e7de950ad3",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "source_full = cv2.imread(\"/content/ПАЛЬЧУНОВ.png\")\n",
    "source_full"
   ],
   "metadata": {
    "id": "_bSjjpp8csvl",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#@markdown #**Upload source image and video**\n",
    "\n",
    "#@markdown choose not really long videos, coz it can take a lot of time otherwise  \n",
    "\n",
    "#@markdown choose source image as a photo -- preferable a selfie of a person\n",
    "\n",
    "target_type = 'image' #@param [\"video\", \"image\"]\n",
    "\n",
    "\n",
    "source_path = '/content/ПАЛЬЧУНОВ.png' #@param {type:\"string\"}\n",
    "target_path = '/content/Маск.jpeg' #@param {type:\"string\"}\n",
    "path_to_video = '/content/nggyup.mp4' #@param {type:\"string\"}\n",
    "\n",
    "source_full = cv2.imread(source_path)\n",
    "OUT_VIDEO_NAME = \"examples/results/result.mp4\"\n",
    "crop_size = 224 # don't change this\n",
    "\n",
    "\n",
    "# check, if we can detect face on the source image\n",
    "\n",
    "try:    \n",
    "    source = crop_face(source_full, app, crop_size)[0]\n",
    "    source = [source[:, :, ::-1]]\n",
    "    print(\"Everything is ok!\")\n",
    "except TypeError:\n",
    "    print(\"Bad source images\")\n",
    "\n",
    "# read video\n",
    "if target_type == 'image':\n",
    "    target_full = cv2.imread(target_path)\n",
    "    full_frames = [target_full]\n",
    "else:\n",
    "    full_frames, fps = read_video(path_to_video)\n",
    "target = get_target(full_frames, app, crop_size)"
   ],
   "metadata": {
    "id": "gRNla-XdtDO5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6c6cdcaa-742e-494e-85da-4026e189344d",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#@markdown #**Inference**\n",
    "\n",
    "\n",
    "batch_size =  40#@param {type:\"integer\"}\n",
    "\n",
    "START_TIME = time.time()\n",
    "\n",
    "final_frames_list, crop_frames_list, full_frames, tfm_array_list = model_inference(full_frames,\n",
    "                                                                                   source,\n",
    "                                                                                   target,\n",
    "                                                                                   netArc,\n",
    "                                                                                   G,\n",
    "                                                                                   app,\n",
    "                                                                                   set_target = False,\n",
    "                                                                                   crop_size=crop_size,\n",
    "                                                                                   BS=batch_size)\n",
    "\n",
    "if use_sr:\n",
    "    final_frames_list = face_enhancement(final_frames_list, model)\n",
    "\n",
    "if target_type == 'video':\n",
    "  get_final_video(final_frames_list,\n",
    "                  crop_frames_list,\n",
    "                  full_frames,\n",
    "                  tfm_array_list,\n",
    "                  OUT_VIDEO_NAME,\n",
    "                  fps, \n",
    "                  handler)\n",
    "  \n",
    "  add_audio_from_another_video(path_to_video, OUT_VIDEO_NAME, \"audio\")\n",
    "\n",
    "  print(f'Full pipeline took {time.time() - START_TIME}')\n",
    "  print(f\"Video saved with path {OUT_VIDEO_NAME}\")\n",
    "else:\n",
    "  result = get_final_image(final_frames_list, crop_frames_list, full_frames[0], tfm_array_list, handler)\n",
    "  cv2.imwrite('examples/results/result.png', result)"
   ],
   "metadata": {
    "id": "PzPhKk5PAQHe",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "cfda1c57-ad24-4728-9e96-2fd747688032",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#@markdown #**Visualize Image to Image swap**\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "show_images([source[0][:, :, ::-1], target_full, result], ['Source Image', 'Target Image', 'Swapped Image'], figsize=(20, 15))\n"
   ],
   "metadata": {
    "id": "cG3i9mwudUu-",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "outputId": "9221ab74-3c16-4648-86c7-b4bd39cdfac2",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#@markdown #**Visualize Video Swap**\n",
    "\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "video_file = open(OUT_VIDEO_NAME, \"r+b\").read()\n",
    "video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
    "\n",
    "HTML(f\"\"\"<video width={800} controls><source src=\"{video_url}\"></video>\"\"\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "iqOjUHPPbVZI",
    "outputId": "1b957d80-31a8-4f4d-9d4a-6a9f9710df73",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
